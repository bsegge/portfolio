{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Frequency - Inverse Document Frequency; Text Analytics in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we generate random text that will be used later in the model\n",
    "\n",
    "text = [\n",
    "    [\"I really like chicken flavored ramen noodles.\",'food'],\n",
    "    [\"I don't normally use coupons to buy groceries, even though I know you can save money.\",'food'],\n",
    "    [\"Mediterranean cuisine is my favorite.\",'food'],\n",
    "    [\"I drive a 2014 Ford Focus SE, but my dream car is a Toyota Tacoma.\",'car'],\n",
    "    [\"Dark blue is the color I want my dream car to be.\",'car'],\n",
    "    [\"I go to the University of Denver. I started in 2018 and expect to finish in 2020. I'm going for my masters of science in Data Science\",'school'],\n",
    "    [\"The University of Denver is not like Michigan State University, which is public and has many more students than DU.\",'school'],\n",
    "    [\"Pizza is my favorite food, even if that's pretty lame\",'food'],\n",
    "    [\"The Toyota Tacoma is a truck that a lot of people have in Colorado. It's great because it's a small truck, but handles well in the mountains.\",'car'],\n",
    "    [\"Michigan State University is a great school\",'school'],\n",
    "    [\"University of Michigan is Michigan State University's rival. A lot of people go to U of M, but clearly Michigan State University is better.\",'school'],\n",
    "    [\"There are a lot of places to eat in downtown Denver. One of my favorites is La Loma.\",'food'],\n",
    "    [\"Driving down I-25 can be a pain. Often, it is busy and there is a lot of traffic. They are working on the roads now, which causes further congestion.\",'car'],\n",
    "    [\"Sometimes I shop at King Soopers, and sometimes I shop at Safeway. I haven't decided which is my favorite grocery store, yet.\",'food'],\n",
    "    [\"There are many companies that make cars. You have Ford, Toyota, Honda, Hundai, Dodge, Chrysler, Chevrolet, and many more.\",'car'],\n",
    "    [\"I'm excited for the advent of autonomous driving. I think it will improve traffic congestion, as well as road safety. Plus, I will be able to nap while 'driving'\",'car'],\n",
    "    [\"My friend drives a Jeep. I don't think I'd ever buy one, as I've heard many negative stories about them, but to each his or her own.\",'car'],\n",
    "    [\"Intermittent Fasting is the idea of eating during a specified shortened window during the day. The goal is help your digestion, and give your body a rest by not eating every minute of every day.\",'food'],\n",
    "    [\"On the Fourth of July, in America, many people head outside to a park or backyard and grill hotdogs, burgers, and bratwursts. It's a lot of fun\",'food'],\n",
    "    [\"There are many different types of cuisines in America. You can find alost anything.\",'food'],\n",
    "    [\"I haven't found a pizza place in Denver that I really like, yet\",'food'],\n",
    "    [\"Once I finish my masters, I plan to look for a full time job somewhere in Denver.\",'school'],\n",
    "    [\"I enjoy being a student. The atmoshphere is great, and I get a lot of student discounts!\",'school'],\n",
    "    [\"I'm building this model as a demonstration of my knowledge and skills.\",'school'],\n",
    "    [\"There are many things I still hope to learn, and I'm eager for my classes this quarter.\",'school'],\n",
    "    [\"My favorite class so far has been Python programming, but I can tell I'm going to enjoy Data Mining.\",'school'],\n",
    "    [\"Probability and Statistics was a tough class, but I'm grateful for it. The class taught me a great deal, and really set the foundation for future learning.\",'school'],\n",
    "    [\"Now that my resume is becoming more robust with Data Science experience, I'm starting to get offers from various companies.\",'school']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "\n",
    "df = pd.DataFrame(text, columns = ['text','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minor text processing\n",
    "\n",
    "def text_process(dataframe, column_to_prep):\n",
    "    \"\"\"\n",
    "    Removes whitespace, special characters, and stop words\n",
    "    \n",
    "    input: dataframe(pandas dataframe)\n",
    "           column_to_prep(str)\n",
    "           \n",
    "    output: dataframe(pandas dataframe)\n",
    "    \"\"\"\n",
    "    \n",
    "    # lowercase all text\n",
    "    dataframe[f'{column_to_prep}'] = dataframe[f'{column_to_prep}'].str.lower()\n",
    "    \n",
    "    # remove whitespace\n",
    "    dataframe[f'{column_to_prep}'] = dataframe[f'{column_to_prep}'].str.strip()\n",
    "    \n",
    "    # remove stop words\n",
    "    dataframe[f'{column_to_prep}'] = (dataframe[f'{column_to_prep}']\n",
    "                                      .apply(lambda x: ' '.join([i for i in x.split() if i not in stopwords])))\n",
    "    \n",
    "    # remove punctuation\n",
    "    dataframe[f'{column_to_prep}'] = dataframe[f'{column_to_prep}'].str.replace('[^\\w\\s]','')\n",
    "    \n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating column of word count in df\n",
    "\n",
    "def word_count(dataframe, column_to_count):\n",
    "    \"\"\"\n",
    "    Counts the frequency of words in a document\n",
    "    \n",
    "    input: dataframe(pandas dataframe)\n",
    "           column_to_prep(str)\n",
    "           \n",
    "    output: frequency(int)\n",
    "    \"\"\"\n",
    "    words = dataframe[f'{column_to_count}'].apply(lambda x: word_tokenize(' '.join([i for i in x.split()])))\n",
    "    dataframe['num_words'] = [len(i) for i in words]\n",
    "    \n",
    "    return(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary with total word counts and inverse frequency\n",
    "\n",
    "def freq_dict(dataframe, column_to_count):\n",
    "    \"\"\"\n",
    "    Counts the frequency of words in all text\n",
    "    \n",
    "    input: dataframe(pandas dataframe)\n",
    "           column_to_prep(str)\n",
    "           \n",
    "    output: word_dict(dictionary: [count, inverse frequency])\n",
    "    \"\"\"\n",
    "    \n",
    "    word_dict = {}\n",
    "#     dataframe = text_process(dataframe, f'{column_to_count}')\n",
    "\n",
    "    for i in dataframe[f'{column_to_count}'].str.split().apply(pd.Series).stack():\n",
    "        if i in word_dict:\n",
    "            word_dict[i] += 1\n",
    "        else:\n",
    "            word_dict[i] = 1\n",
    "\n",
    "    for k,v in word_dict.items():\n",
    "        word_dict[k] = [v, np.log(len(df)/v)]\n",
    "\n",
    "    return(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepping our data using the functions we built\n",
    "\n",
    "df = word_count(text_process(df, 'text'),'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the word count frequency matrix\n",
    "\n",
    "doc_li = [i for i in df.text.str.split()]\n",
    "col_li = sorted(list(freq_dict(df,'text').keys()))\n",
    "freq_li = [[0 for i in range(len(col_li))] for j in range(len(doc_li))]\n",
    "                \n",
    "for doc_idx, doc in enumerate(doc_li):\n",
    "    for word in doc:\n",
    "        for idx, col in enumerate(col_li):\n",
    "            if word == col:\n",
    "                freq_li[doc_idx][idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining word count and setting index to document text data\n",
    "\n",
    "word_freq_mat = pd.DataFrame(np.matrix(freq_li), columns=col_li).join(df[['text','num_words']]).set_index('text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting values to term frequency\n",
    "\n",
    "word_freq_mat = word_freq_mat.iloc[:,0:-1].div(word_freq_mat.num_words, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding inverse document frequency\n",
    "\n",
    "word_freq_mat.loc[len(word_freq_mat)] = [i[1] for i in list(freq_dict(df, 'text').values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiplying tf by idf to get tfidf\n",
    "\n",
    "word_freq_mat = word_freq_mat.iloc[:-1,:].mul(word_freq_mat.iloc[-1,:].values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it! We now have a Term Frequency-Inverse Document Frequency matrix. With these newly dervied numerical variables we can fit a machine learning model (random forest, in this case) and use it to predict the classifications of future documents based on their word composition. \n",
    "\n",
    "<b>Note</b>: we are only using 10 documents to train this model, and therefore our corpus is small and our training will be light. I don't expect a high accuracy, but this can of course be improved with more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(word_freq_mat)\n",
    "y = df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 2]\n",
      " [0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\seggebru\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.00      0.00      0.00         1\n",
      "        food       1.00      0.33      0.50         3\n",
      "      school       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.47      0.44      0.36         6\n",
      "weighted avg       0.63      0.50      0.44         6\n",
      "\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the above was for demonstration and edification purposes. Fortunately, a lot of the prep work has been done for us in sklearn's TfidfVectorizer() function. We set the min_df parameter to 2 to specify that a word included in the corpus must be present in at least 2 of the documents. This helps prevent irrelevent words from being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['america', 'buy', 'car', 'class', 'companies', 'congestion', 'data', 'denver', 'dont', 'dream', 'driving', 'enjoy', 'favorite', 'finish', 'ford', 'going', 'great', 'havent', 'im', 'its', 'like', 'lot', 'masters', 'michigan', 'people', 'pizza', 'science', 'state', 'tacoma', 'think', 'toyota', 'traffic', 'university']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=2, max_df=0.7)\n",
    "X = tfidfconverter.fit_transform(df.text)\n",
    "print(tfidfconverter.get_feature_names())\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the matrix is built, we can run it through the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 3 0]\n",
      " [0 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\seggebru\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         car       0.00      0.00      0.00         1\n",
      "        food       0.60      1.00      0.75         3\n",
      "      school       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.67         6\n",
      "   macro avg       0.53      0.50      0.47         6\n",
      "weighted avg       0.63      0.67      0.60         6\n",
      "\n",
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great predictive power, but of course we expected this. We simply need more data to tune the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
